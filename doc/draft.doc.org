#+STARTUP: showall indent hidestars
#+TOC: headlines 3

* Overview

Components:
- airdropper
- proxy
- indexer
- faucet

Some strange things (services):
- neon_test_invoke_program_loader
- dbcreation
- solana
- proxy_net

proxy-model.py

We have separated services for proxy and indexer and other components. All of them starts from ~proxy-model.py/proxy/testing/docker-compose-test.yml~

In directory ~proxy-model.py/proxy~ we have:
- indexer
- mempool
- proxy
- neon_rpc_api_model

..and ~testing~. From folder testing we can starts all components, see docker-compose-test.yml

* Mempool

#EntryPoint: proxy/neon_rpc_api_model/neon_rpc_api_worker.py

#ProcessList:
#+BEGIN_SRC sh
  /bin/bash proxy/run_test_proxy.sh
     /bin/bash proxy/run_proxy.sh
        /python3 -m proxy --hostame 0.0.0.0 --port 9090 --enable-web-server --plugins proxy.plugin.NeonRpcAPiPlugin
#+END_SRC

#EntryPoint: proxy/neon_proxy_app.py
This is entry point of NeonProxyApp.

In the init() and start() starts:
- service MPService - Mempool and
- service ProxyStatService (stats for Prometheus)

Plugin accept connections from the users and processes (_process_request at proxy/plugin/neon_rpc_api_plugin.py) for example request from Etheriim Clients

getModel starts hadling process request and have thread local variables (actually global python process) for processing, implements sigleton, locks, etc.

See handle_request at proxy/plugin/neon_rpc_api_plugin.py
- accept http-request
- parse input json
- call _process_request
  - dispatch method for processing request

All methods were imlemented in neon_rpc_api_worker. Method should have prefix like "neon_", "web3_", "eth_".

Proxy have private methods, which could be called from local nodes, see ~private_method_set~

Each entrypoint has own client for the Mempool and if request should be send to the Mempool it will be sent by the call of the method. For example when user create Etherium transaction at the first moment it should call the methods to get the transaction which were processed on the network use this number as nonce in the Etherium transaction.

When user sent several transactions to the network and they not accepted by the network to the blocks, such transactions has tag "pending". They ready to input into blocks, but may be lowest price etc. See eth_GetTransactionCount for reference.

If tag is "pending", to get the latest transaction from it, to return to the Client. Each method of the mempool_client.py will be create request structure like MPPendingTxNonceRequest and then it will be sent to the Mempool.

On Mempool service (are placed into proxy/mempool/mempool_service.py) when Mempool will accept this request it will be process (def process_mp_request). There is dispatcher, it can be:
- SendTransaction
- GetPendingTransactionNonce
- ...

In addition (doesnt exists on Etherium) there is another functuions needs for processing Solana functions.

Also in the Mempool we store the latest gas price. It is need to the filter transactions which is possble to execute.

And we can process request about last parameters of the NeonEVM (def getElfParamDict).

After receive request from the user, requst sended to the mempool_service.py, to dispatch request, go to the dictionary of pending transactions (by sender), we will get the last nonce in the mempool, and return to the worker. Worker to get the last Nonce from the for what? [TODO:gmm] Explain it.

Mempool chech and choose value, which will return.

If we compact transaction without any problem, then we try to get the recive for such transaction. Becouse transaction can be already pricessed by the Solana. We sholdn't sent to Client transactions, which already known. We do "precheck" (see eth_SendRawTransaction at neon_rpc_api_model/neon_rpc_api_worker.py). On this step we check the fields of the transaction, for example check the Nonce is valid value, check the Gas in the limits, check chain_id, size of the transaction.

After than we will emulatate of the transaction (see precheck at transaction_validator.py which call emulator_intractor.py). We use NeonCLI for it. NeonCLI will accept transaction, parse it, and will try to execute, load contract from the Solana node, retrieve data from Solana node. On the end of execution NeonCLI will be return the result of execution, of something goes wrong it will return the error. We will check the returned value. We can see text of error in our Metamask which contains text from the Solana.

Then we prevalidate (see prevalidate_tx at transaction_validator) for checking limits of out platform? for example account size in the Solana, estimate gas limits in the transaction. If something goes wrong we will return.

Check for EIP 1055) [TODO:gmm] - explain it.

After it we add tx to the list txs for execution (see add_tx at mempool_schedule.py). If transaction already exists on the Mempool we will return error to the Client. If transaction has the same Nonce we will check the gas_price and replace transaction in the Mempool by increased gas_price.

A mempool has a capacity, and if there are too many transactions, we drop transactions with a lower gas price (see check_oversized_and_reduce at mempool_schedule.py)

If everything is okay, transaction will be accepted and answer will be returned to worker. Worker check the answer. If is okay, worker returns the hash of transaction, otherwise handle of errors (see ::561 at neon_rpc_api_worker.py).

Mempool has a task, which run periodically throuth event-loop for execute transactions (see begin of mempool/mempool.py and process_tx_schedule_loop).

Mempool has list of workers which will be executed of transaction. When the project was started the Solana-library for python was implemented it only in sync-mode. This way Mempool doesnt send transaction directly to Solana. Instead of it Mempool uses additional process (a lot of it's)

process_tx_shedule_loop at mempool/mempool.py is responsible of it. It check the available executor, enqueue_tx_request(), select transaction by the highest price. And if gas_price is enought transcation will be proceessed by the proxy. If not, such transactions will not, it will continue waiting for gas_price goes down.

Also for transaction processing we need additional ~resources~ for processing. We need:
- the account which will pay for transaction execution
- the acconts which store EVM state for iterative mode for transaction execution
- the accounts which store the Etheriuim transaction if the size of transaction is biggest them limit of Solana trasaction (1400 bytes in 2 packets, Etherium transaction can be 100 kB)

If transaction is big, first step is we will price the transaction to the Solana account and then we will call NeonEVM program to process it.

After choose the transaction (in enqueue_tx_request()) and resources then we send (~executor_mng.submit_mp_request(tx)~)

mempool/mempool_executor contains the ~Executor.

Executor has a several tasks which process and first and important of it is ~exec_neon_tx_task.execute_neon_tx(tx). Implemetation of it use NeonTxSendStrategyExecutor which provide several stategyes depend of tx characteristics:

| tx small by size and gas    | process by one Solana tx (SimpleNeonTxStrategy)                                              |
| tx is big                   | IterativeNeonTxStrategy                                                                      |
| tx is big                   | save to the Solana account (HolderNeonTxStrategy)                                            |
| tx has more the 43 accounts | use additional tx for create AddressLookupTables for increase accs (ALTSimpleNeonTxStrategy) |
|                             | [TODO:gmm] Other strategyes implememted in mempool executor?                                 |

When Executor receive tx for execution, it will choose the strategy for execution (def execute). Each Strategy will check the parameters of tx and if it can processed - it will processed. If it cannot it return the False on the Validate-step and Executor will try the next Strategy. Strategy method validate check the exeption for checking appropriate txs.

About transaction with Address Lookup Tables:

[TODO:gmm] - I cannot understand explanation it on 41:41, need return to it after read how to Solana works, and try again

The transaction processing will be splitted on the several steps. On each step we should wait the result of execution. For example, before we using addres in lookup tables in Solana transaction we should do the several steps:
- create the address lookup tables
- wait it will be created
- receive information of adress lookup tables was created when Solana block is generated
- then we should write addres of the account which will be used into addres lookup tables
- and wait the next block of Solana, becouse only after block generated, Solana returns path the receive to execution
- after that we should wait one block, becouse it impossible use address lookup table in the same block
- only after thet we can create Solana transaction for NeonEVM program which will use addres lookup tables, which created on the previous steps

So, thats mean then we should choose the simplest type of transactions for Etherium transaction, which we writen to Solana account before execution with address lookup tables will require about 3 Solana blocks gets the result of execution. On the first block we will create the address lookup table and write Etherium transaction into Solana account, we will wait the receives of execution of this transactions. Then we will write account into addres lookup tables and wait till this block will be generated and confirmed by the Solana cluster. And only after that we will send the transaction for NeonEVM execution.

_make_tx_step_ix creates the Solana transaction and contaions pubkeys refernces:

| _holder                | account with Etherium transaction                                      |
| _operator_account      | which it will be paid for the Solana tx execution                      |
| _treasure_pool_address | pool which operator uses for pay for fee Neon tx processing            |
| _operator_neon_address | account which use for pay for operator ([TODO:gmm] - What?)            |
| SYS_PROGRAM_ID         | need include to the list of accounts, because it's required by NeonEVM |
| _evm_program_id        | address of out EVM programm                                            |

also we add the list of accounts, wich will be used during Etherium-like transaction execution

[TODO:gmm] -=HERE=- 48:56


* Indexer

#EntryPoint: ~proxy/indexer/indexer_app.py~
#Purpose:
- collecting statistic from Prometeus
- indexer application
  - collect information about completed NEON transactions on Solana
  - index them
  - store index into Postgres

** How it works

class ~IndexerDB~:
- contains db-connection
- methods:
  - sol_blocks_db - information about completed blocks
  - neon_tx_db - info about NEON transactions, bpf-cycles, EVM-steps, used head_size and so on. Need for stats.
  - neon_tx_logs_db -about events happened diring transactions execution in contracts
  - sol_tx_costs_db - additional information about how many NEON tokens owned with NEON transactions execution and how many SOL-tokens was spent in transaction

Indexer starts
- IndexerStatClient to the Prometeus
- Collectors - collect information about competed Solana transactions
  - finalized
  - confirmed

Other components:
- Ix-Decoder - something about instrtuctions in NEON EVM [TODO:gmm] ?

#EntryPoint starts from collecting finalized transactions from Solana blocks, then collect info about confirmed blocks.

When finalized collector starts (~FinalizedSolTxMetaCollector~), collector will get the last block of the finalized part of the history and iterate throuht all blocks of it.

Collector have different logic for processing finalized and confirmed data.

Collector ask Solana for getting the list of transactions signatures, which were executed for address throught rpc-request ~getSignaturesForAddress~ (see Solana documentation). It's Solana-address of our NEON EVM. [TODO:gmm] - for what?

This rpc api call returns limited list of signatures backward in time. Becouse of that, when we need more deeper in history we need ask Solana with optinal parameters ~limit~ and ~before~. We use for it method ~_build_checkpoint_list~ in procedure iter_tx_meta.

This is how we get all the historical data and put it into the database in ~_save_checkpoint~.

When the data is received, we start getting information about the transactions.

During processing, we retrieve the body of the transactions using the method _iter_tx_meta which use rpc call to Solana ~getTransaction~ (see Solana documetation)

[TODO:gmm] Need understand Solana's block format description. For example I do not undestand what is addressTableLookps in the body of transactions

For confirmed transactions logic is more simple because we dont need save checkpoints.

~run_sol_tx_collector~ saves data to database. It call subroutine ~locate_neon_block~ for try to get the block, and here we have interesting point.

Since a single transaction can be distributed over several blocks, and there may be several blocks between the beginning and the end of the transaction that do not contain data for that transaction, the array of blocks is tied with a linked list. Moving through this linked list we don't need to go through the blocks which don't contain the data we need.

The code calls it a "deque", but it looks more like a "sparse array" to me.

After return to ~run_sol_tx_collector~ collector will parse each instructions by the special decoder. Information about instructions collected (~iter_sol_neon_ix~). There is class SolTxReceiptInfo which filtered only NEON instructions.

[TODO:gmm] - I don't quite understand why we need to parse instructions and how this affects processing.

Solana transactions ~logMessages~ are a way for NeonEVM to tell Indexer what happened during transaction execution. They base64 encoded. From here we can get the hash of each transaction. The code responsible for this can be found ~common_neon/utils/evm_log_decoder.py~. It allows you to extract not only hash, but also returns, events, gas usege for cancelled transactions, and gas for each iteration.

If I understand correctly, it is necessary to decode NeonEVM transactions to find the holder of the transaction and write this data to the index, but this is just a guess.

Anyway, after decoding, if the transaction is in the "done" status, it is saved in the database.

When a new NEON block is completed the statistics are sent to the Prometheus server, and the block itself is saved to the database (~submit block~). Stored info about the block, transactions, logs, events, costs (~set_tx_list~). Class ~NeonTxDB~ contains list of columns.

If current stored block is finalized ~_complete_neon_block~ do special logic for finalized blocks for mapping history data for this block (see ~finalize_block_list~ for details)

In additions info about last parsed blocks (chechpoints) are stored for case, when indexer will be restart.

Proxy will use this information for the Etherium Client (see ~eth_getBlockTransactionCountByHash~ and get_block_by_hash~ at proxy/neon_rpc_api_model/neon_rpc_api_worker.py for example).'

If database doesn't contains block, it wilk generate fake block (see ~_block_from_value~ and ~_generate_fake_block_hash~). Proxy doesn't pull fake blocks from database, instead of it proxy returns empty block (doesn't contans transactions but formatted properly, with zeroes in data fields).

** Data structures

~ix_decoder_list~ at indexer/indexer.py contains list of instrucions if NeonEVM. The same file contains the transaction ~executor~ (class WriteHolderAccountIx)

** TODO What do we need to explain

- format of the Solana blocks and transactions, finalized and confirmed
- branches in Solana
- decription of NeonEVM (commands)
